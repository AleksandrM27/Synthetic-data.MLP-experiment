import pandas as pd
import numpy as np
from scipy.stats import entropy, ks_2samp, wasserstein_distance
import warnings
warnings.filterwarnings("ignore")

np.random.seed(42)

Загрузка данных
df = pd.read_excel()
train_columns = [col for col in df.columns if "Train" in col]

synthetic_data = {}
comparison_metrics = []

Генерация GBM
for col in train_columns:
    series = df[col].dropna().values
    n = len(series)

    # Оценка μ и σ из лог-доходностей
    log_returns = np.diff(np.log(series))
    mu = np.mean(log_returns)
    sigma = np.std(log_returns)
    dt = 1.0

    Генерация GBM
    gbm = [series[0]]
    for _ in range(1, n):
        z = np.random.normal()
        next_price = gbm[-1] * np.exp((mu - 0.5 * sigma ** 2) * dt + sigma * np.sqrt(dt) * z)
        gbm.append(next_price)

    syn_col = col.replace("Train", "GBM")
    synthetic_data[syn_col] = np.array(gbm)

    # --- Метрики ---
    real_hist, bins = np.histogram(series, bins=50, density=True)
    synthetic_hist, _ = np.histogram(gbm, bins=bins, density=True)

    kl_div = entropy(real_hist + 1e-8, synthetic_hist + 1e-8)
    ks_stat, _ = ks_2samp(series, gbm)
    w_dist = wasserstein_distance(series, gbm)

    comparison_metrics.append({
        "Fold": col,
        "μ": mu,
        "σ": sigma,
        "KL-дивергенция": kl_div,
        "KS-статистика": ks_stat,
        "Wasserstein-дист.": w_dist
    })

Сохранение синтетики
synthetic_long = []
for col, values in synthetic_data.items():
    for i, v in enumerate(values):
        synthetic_long.append({
            "Fold": col,
            "Index": i,
            "Value": v
        })

synthetic_df = pd.DataFrame(synthetic_long)
synthetic_df.to_excel("CV_Oil_Synthetic_GBM_Long.xlsx", index=False)

Сохранение метрик
metrics_df = pd.DataFrame(comparison_metrics)
print(metrics_df.to_string(index=False))
metrics_df.to_excel("CV_Oil_Synthetic_GBM_Metrics.xlsx", index=False)
